[
  
    {
      "title"    : "Jump Game",
      "article"  : "<div class='article col col-12 animate'> <div class='article__inner'> <div class='article__content'> <h2 class='article__title'> <a href='/jm-gm'>Jump Game</a> </h2> <p class='article__excerpt'>Jump Game</p><div class='article__bottom'> <div class='article-tags__box'><a href='/tag/dp' class='article__tag'>dp</a><a href='/tag/dynamic-programming' class='article__tag'>dynamic-programming</a><a href='/tag/optimization' class='article__tag'>optimization</a><a href='/tag/recursion' class='article__tag'>recursion</a></div></div></div></div></div>",
      "category" : "",
      "tags"     : "dp, dynamic-programming, optimization, and recursion",
      "url"      : "/jm-gm",
      "date"     : "2022-06-18 10:00:00 +0400",
      "content"  : "  Problem: Given an array of non-negative integers nums, you are initially positioned at the first index of the array. Each element in the array represents your maximum jump length at that position. Your goal is to reach the last index in the minimum number of jumps. You can assume that you can always reach the last index.Let’s look at two different approaches:1. Recursive [without memoization]Basically checking for possible range on each element.possible_jumps = { curr + [1..nums[idx]] } Basically, we are checking for all possible options. Range space is: [1..nums[idx]], jump space will be: idx + [1..nums[idx]]def solve(nums):    import math    def recurse(idx):        if idx == len(nums) - 1:            return 0        if idx &amp;gt;= len(nums):            return math.inf # not possible, it is beyond the n&#39;th element        res = math.inf        val = nums[idx] # we will check for all possible jumps, range: [1..nums[idx]] (inclusive)        for v in range(1, val + 1):            res = min(res, 1 + recurse(idx + v))        return res    return recurse(0)2. Dynamic Programming [Bottom Up], Push DPFor DP State Relations, take a look into the following picture: Base state for dp[0] will be 0, because cost of reaching to idx=0 is ZERO. class Solution:    def jump(self, nums: List[int]) -&amp;gt; int:        return self.dpsolve(nums)    def dpsolve(self, nums):        import math        n = len(nums)        dp = [math.inf] * n        dp[0] = 0        for i in range(0, n):            for v in range(1, nums[i]+1):                if i + v &amp;lt; n:                    dp[i+v] = min(dp[i]+1, dp[i+v])        return dp[n-1]"
    } ,
  
    {
      "title"    : "Manacher&#39;s Algorithm",
      "article"  : "<div class='article col col-12 animate'> <div class='article__inner'> <div class='article__content'> <h2 class='article__title'> <a href='/mn-ch'>Manacher&#39;s Algorithm</a> </h2> <p class='article__excerpt'>Longest Palindromic Substring</p><div class='article__bottom'> <div class='article-tags__box'><a href='/tag/string' class='article__tag'>string</a><a href='/tag/palindrome' class='article__tag'>palindrome</a><a href='/tag/longest-palindrome' class='article__tag'>longest-palindrome</a><a href='/tag/manacher's-algorithm' class='article__tag'>manacher's-algorithm</a></div></div></div></div></div>",
      "category" : "",
      "tags"     : "string, palindrome, longest-palindrome, and manacher's-algorithm",
      "url"      : "/mn-ch",
      "date"     : "2022-06-13 10:00:00 +0400",
      "content"  : "There are multiple different ways of implementation for this problem, like DP(lcs, etc), expanding from center.But the most optimal approach is Manacher’s Algorithm, time complexity: O(n).It’s core idea is calculating current palindrome information based on previous calculated palindrome information.Let’s draw it and see some formulas and implications.Some formulas &amp;amp; implications:To handle both even &amp;amp; odd lengths we need some preprocessing on string. It will be like this: ‘@#s#t#r#$’There will be: n string chars + (n+1) ‘#’ symbol + 1 ‘@’ symbol + 1 ‘$’ symbol = 2n + 32n+3 =&amp;gt; will be odd alwayscenterPos =&amp;gt; is current center which expanded longer distance  centerLeft + d = centerPos  centerRight - d = centerPos  centerLeft + centerRight = 2*centerPos  centerLeft + x = currentLeft (or mirror of currentRight)  x = d - i = centerRight - i  centerLeft + centerRight - i = currentLeftImportant implication: currentLeft (mirror) = 2*centerPos - iBut there could be two different cases:  currentLeft - distance[currentLeft] &amp;gt; centerLeft [it means it’s within borders of the centerLeft…centerPosition]  currentLeft - distance[currentLeft] &amp;lt; centerLeft [it means it’s out of borders of the centerLeft..centerPosition]For the second case, we don’t know about the out of border information, therefore we need to cut until the border. [centerRight-currentLeft]    def manachersSolve(self, s: str) -&amp;gt; str:        # processing str = @#s#a#l#a#m#$        newlen = 2*len(s) + 3        newstr = [&#39;@&#39;]        newstr += [f&#39;#{c}&#39; for c in s]        newstr += [&#39;#$&#39;]        newstr = &#39;&#39;.join(newstr)        p = [0] * newlen        maxlen = 0        centerPos = 0        centerLeftPos = 0        centerRightPos = 0        # centerRightPos - d = centerPos        # centerLeftPos + d = centerPos        # centerRightPos + centerLeftPos = 2*centerPos        # if centerPos + p[centerPos] &amp;gt; centerPos + i [inside]        # if centerPos + p[centerPos] &amp;lt; centerPos + i [outside]        # if centerPos - p[centerPos] &amp;lt; centerPos - i [inside]        # if centerPos - p[centerPos] &amp;gt; centerPos - i [outside]        for i in range(1, newlen-1):            if i &amp;lt; centerRightPos:                p[i] = min(centerRightPos-i, p[2*centerPos - i])            while (newstr[i-p[i]-1] == newstr[i + p[i] + 1]):                p[i] += 1            if (i + p[i] &amp;gt; centerRightPos):                centerPos = i                centerRightPos = centerPos + p[i]            if p[i] &amp;gt; maxlen:                start = (i-p[i]-1)//2                maxlen = p[i]        return s[start:start+maxlen]"
    } ,
  
    {
      "title"    : "Convert to ZigZag",
      "article"  : "<div class='article col col-12 animate'> <div class='article__inner'> <div class='article__content'> <h2 class='article__title'> <a href='/zg-zg'>Convert to ZigZag</a> </h2> <p class='article__excerpt'>Convert to ZigZag</p><div class='article__bottom'> <div class='article-tags__box'><a href='/tag/string' class='article__tag'>string</a><a href='/tag/zig-zag' class='article__tag'>zig-zag</a></div></div></div></div></div>",
      "category" : "",
      "tags"     : "string and zig-zag",
      "url"      : "/zg-zg",
      "date"     : "2022-06-09 09:00:00 +0400",
      "content"  : "  Problem: Print the string “SALAM” in a zigzag pattern on a given number of rows.I will try to explain my approach, don’t know if someone tried to solve in this way.There are four key observations here:Observation#1:If number of rows is equal to or greater than length of the string, string will not jump to other columns (not enough string to spread other columns).If number of rows is equal to 1, the same thing.Observation#2:We can see two different waves. Down-&amp;gt;Up, Up-&amp;gt;DownThey are changing on each iteration.We can visualize these waves as following:Observation#3:We can think about parallel columns as a square. As we can see, distance between parallel column chars is:For Down-&amp;gt;Up: distance = heightOfSquare + diagonalOfSquare = (m-i) + (m-i) (i is 1 based index)For Up-&amp;gt;Down: distance = diagonalOfSquare + heightOfSquare = (i-1) + (i-1) (i is 1 based index)Let’s draw it.Observation#4:If you take attention to header and footer points of waves, their direction is not changing, remains the same on each iteration. Reason? because it completes one full PERIOD, and doesn’t change it’s direction. (it’s similar to the physic’s wave funcions :) )By considering these observations, let’s implement:def convert(self, s: str, numRows: int) -&amp;gt; str:    ans = &#39;&#39;    n = len(s)    m = numRows    if (m==1) or (n &amp;lt;= m):        return s    for i in range(1, m+1):        direction = 0 # starting with Down        startIdx = i-1        ans += s[startIdx]        while (startIdx &amp;lt; n):            if i == 1:                direction = 0 # set direction to down (header&#39;s direction is always down)            elif i == m:                direction = 1 # set direction to up (footer&#39;s direction is always up)            if not direction:                stepsize = 2*(m-i) # heightOfSquare + diagonalOfSquare = (m-i) + (m-i)            else:                stepsize = 2*(i-1) # diagonalOfSquare + heightOfSquare = (i-1) + (i-1)            nextIdx = startIdx + stepsize # update next possible position            startIdx = nextIdx # next start position will be current next position            if nextIdx &amp;lt; n: # if there is char in nextIdx add it to the result                ans += s[startIdx]            direction ^= 1    return ans"
    } ,
  
    {
      "title"    : "Median Of Two Sorted Arrays",
      "article"  : "<div class='article col col-12 animate'> <div class='article__inner'> <div class='article__content'> <h2 class='article__title'> <a href='/two-md'>Median Of Two Sorted Arrays</a> </h2> <p class='article__excerpt'>Median Of Two Sorted Arrays [same &amp; different sizes]</p><div class='article__bottom'> <div class='article-tags__box'><a href='/tag/binary-search' class='article__tag'>binary-search</a><a href='/tag/optimization' class='article__tag'>optimization</a><a href='/tag/median' class='article__tag'>median</a></div></div></div></div></div>",
      "category" : "",
      "tags"     : "binary-search, optimization, and median",
      "url"      : "/two-md",
      "date"     : "2022-06-05 10:00:00 +0400",
      "content"  : "Median Of Two Sorted Arrays [Hidden Patterns of Binary Search]  Problem: Given two sorted arrays nums1 and nums2 of size m and n respectively, return the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)).Everytime I say, if there is some kind of sortedness, there is hidden patterns of binary search usage there ;)First and very basic idea is to merge two arrays and sort them. But in case of sorting merged arrays we will have dismissed the sortedness feature of arrays. But if we can make some clever observations, it can help us to think about the O(log(n)) solution.Simpler Version [same &amp;amp; odd size]As everytime, let’s think simpler version first, both arrays have the same &amp;amp; odd size.  What is median?The median is the value separating the higher half from the lower half of a data sample, a population, or a probability distribution. For a data set, it may be thought of as “the middle” value. [source: wikipedia]Observation#1:Do we need all the elements of the array to calculate median?Actually, NO.Observation#2:Let’s think that we have two sorted arrays:x = [x1, x2, x3]y = [y1, y2, y3]As per their sortedness, we can extract these implications:if x2 &amp;gt; y2, then x2 &amp;gt; {y1} as well.if y2 &amp;gt; x2, then y2 &amp;gt; {x1} as well.According to these key observations, let’s think about the solution gradually.As per the observation#1 we need only middle element(s) to find a median of merged array. Can we reduce our search space by ignoring the elements using observation#2?Before reducing our search space, we have to think about our search space.What is the way of reducing our search space in log(N) time? - # Binary Search.There could be 3 edge cases: [m1==m2, m1&amp;gt;m2, m1&amp;lt;m2]Case 1 if (m1 == m2): Ignore [l1:m1) &amp;amp; (m2:r2], there is not any element between m1 and m2.Case 2 if (m1 &amp;lt; m2): Ignore [l1:m1) &amp;amp; (m2:r2], there are elements between m1 and m2.Case 3 if (m1 &amp;gt; m2): Ignore (m1:r1] &amp;amp; [l2:m2)Implementation:# implementation by A.Kh# time complexity: T(2n) + c  = T(x/2) + c/2 = O(logn)def getMedian(A, size):    if (n % 2 == 0):        return (A[size/2 - 1] + A[size/2])/2    return A[size/2]def solve(X, Y, msize):    if msize==0:        return 0    # remaining 1 elements in each of them [X, Y]    if msize == 1:        return (X[0] + Y[0])/2    m1 = getMedian(X, msize)    m2 = getMedian(Y, msize)    if m1 == m2:        return m1    elif m1 &amp;lt; m2:        return solve(X[msize/2:], Y[:msize/2], msize - msize/2)    elif m1 &amp;gt; m2:        return solve(X[:msize/2], Y[msize/2:], msize - msize/2)A Bit Harder Version [same &amp;amp; (even || odd) sizes]Let’s assume at the end of divide &amp;amp; conquer recursion there are 2 elements remaining in each array (X &amp;amp; Y).How would you calculate median for these remaining elements?Abstract thinking: There are n==2 elements in each X &amp;amp; Y at the end of recursion. x1…xk-2 [{xk-1, xk} {yk-1, yk}] y1…yk-2 Median will be avg of exact middle point two elements in [{xk-1, xk} {yk-1, yk}].How two choose those two values in four?Because of their sortedness, we know that: xk-1 &amp;lt;= xk, yk-1 &amp;lt;= yk.Then, elements arrangement near middle area will be like: min(xk-1, yk-1), max(xk-1, yk-1), min(xk, yk), max(xk, yk), OR min(xk-1, yk-1), min(xk, yk), max(xk-1, yk-1), max(xk, yk). Median: (min(xk, yk) + max(xk-1, yk-1))/2.0 Also, for the search space size, we have to include +1 more space to include element when the size is even.Implementation:# implementation by A.Kh# time complexity: T(2n) + c  = T(x/2) + c/2 = O(logn)def getMedian(A, size):    if (n % 2 == 0):        return (A[size/2 - 1] + A[size/2])/2    return A[size/2]def solve(X, Y, msize):    if msize = 0:        return 0    # remaining 1 elements in each of them [X, Y]    elif msize == 1:        return (X[0] + Y[0])/2    # remaining n==2 elements in each of them [X, Y]    elif msize==2:        return (max(X[0], Y[0]) + min(X[1], Y[1]))/2.0    m1 = getMedian(X, msize)    m2 = getMedian(Y, msize)    if m1 == m2:        return m1    elif m1 &amp;lt; m2:        if msize%2 == 0:            return solve(X[msize/2-1:], Y[:msize/2+1], m-msize/2+1)        return solve(X[msize/2:], Y[:msize/2], msize - msize/2)    elif m1 &amp;gt; m2:        if msize%2 == 0:            return solve(X[:msize/2+1], Y[msize/2-1:], m-msize/2+1)        return solve(X[:msize/2], Y[msize/2:], msize - msize/2)Hard Version [different &amp;amp; (odd || even) sizes]Arrays can have different dimensions.Dividing by half is not obvious here, but we can see an easter-egg observation#3.Observation#3:Let’s think that we have two sorted, different size arrays:x = [x1, x2, x3]y = [y1, y2]merged_array = [i1, i2, i3, i4, i5] {i -&amp;gt; x, y}As you can see here it’s hard to directly apply divide &amp;amp; conquering. We need to reduce this problem into more manageable pieces. At the end of day, we need to find middle element(s) of abstractly merged arrays.As an extenstion to the observation#1, to get median of merged array, we need only middle element(s). So?Core Idea: By using sortedness, can we put such a partition points in x &amp;amp; y which will make first part of the merged array? (up to middle point = (n+m)/2 or (n+m+1)/2)Let’s see it.We need to find such a points in each X &amp;amp; Y. It means position of these pointers will be dependent on each other.Because:[leftPointerX + leftPointerY == (len(X)+len(Y)+1/2)] Another most important observation is: Left elements around middle point should be lesser than right elements. This observation will be main condition for our Binary Search Convergence.# implementation by A.Kh# time complexity: O(log(len(X)))def solve(self, X , Y):        n = len(X)        m = len(Y)        if (n &amp;gt; m):            return solve(Y, X)  # Swapping to make X smaller        start = 0        end = n        mergedMid = (n + m + 1) // 2        while (start &amp;lt;= end):            mid = (start + end) // 2            leftXsize = mid            # Y&#39;s left pointer is dependent on leftX pointer            leftYsize = mergedMid - leftXsize            # checking overflow of indices            # elements before 0th index will be minus infinity (for keeping this conditon TRUE: leftX &amp;lt;= rightY)            # cause there could be edge case: Array X will be completely after Y            leftX = X[leftXsize - 1] if (leftXsize &amp;gt; 0) else float(&#39;-inf&#39;)            # cause there could be edge case: Array Y will be completely after X            leftY = Y[leftYsize - 1] if (leftYsize &amp;gt; 0) else float(&#39;-inf&#39;)            rightX = X[leftXsize] if (leftXsize &amp;lt; n) else float(&#39;inf&#39;)            rightY = Y[leftYsize] if (leftYsize &amp;lt; m) else float(&#39;inf&#39;)            # correct partition is found            if leftX &amp;lt;= rightY and leftY &amp;lt;= rightX:                if ((m + n) % 2 == 0):                    return (max(leftX, leftY) + min(rightX, rightY)) / 2.0                return max(leftX, leftY)            # X size is bigger, decrease X&#39;s size, increase Y&#39;s size for keeping leftX &amp;lt;= rightY            elif leftX &amp;gt; rightY:                end = mid - 1            # Y size is bigger, increase X&#39;s size, decrease Y&#39;size for keeping leftY &amp;lt;= rightX            elif leftY &amp;gt; rightX:                start = mid + 1Further research:  Can we approach this problem as an Order Statistics problem? (finding (k-1)th and kth elements?).  There are diffent but less efficient approaches like mergeSort for this problem (think about it)."
    } ,
  
    {
      "title"    : "Floyd-Warshall [SSSP]",
      "article"  : "<div class='article col col-12 animate'> <div class='article__inner'> <div class='article__content'> <h2 class='article__title'> <a href='/fld-ws'>Floyd-Warshall [SSSP]</a> </h2> <p class='article__excerpt'>All Pairs Shortest Path</p><div class='article__bottom'> <div class='article-tags__box'><a href='/tag/graph' class='article__tag'>graph</a><a href='/tag/dp' class='article__tag'>dp</a><a href='/tag/dynamic-programming' class='article__tag'>dynamic-programming</a><a href='/tag/floyd-warshall' class='article__tag'>floyd-warshall</a><a href='/tag/shortest-path' class='article__tag'>shortest-path</a><a href='/tag/sssp' class='article__tag'>sssp</a></div></div></div></div></div>",
      "category" : "",
      "tags"     : "graph, dp, dynamic-programming, floyd-warshall, shortest-path, and sssp",
      "url"      : "/fld-ws",
      "date"     : "2022-05-28 10:00:00 +0400",
      "content"  : "Floyd-Warshall [Why this idea works?]When I saw this algorithm for a first time, It reminded me the Matrix Chain Multiplication, so therefore didn’t think about that much “how does it work?”, “why does it work?”.Because, MCM problem seems much more interval DP(anyway, it’s acyclic DAG) because of it’s vibe of linearity.Let’s think the problem gradually from simpler to harder, 1. graph is completely linear OR topologically sorted, 2. graph nodes have all the connections pairwise.For simplicity, let’s look at linear graph model.We want to find shortest path between all vertices pairwisely.  Most of the resources about this algorithm shows last state dimension reduced version. So therefore, it’s not that much intuitive for understanding.In linear graph model, let’s think this problem from the combinatorial mind. We can go from 0th vertice to the 3rd vertice via just one path [0-&amp;gt;1-&amp;gt;2-&amp;gt;3]. We can reduce this problem into Matrix Chain Multiplication.   dp[i][j] = min(dp[i][j], dp[i][k]+dp[k][j]) {for k:0..3} Harder version:From the combinatorial mind perspective, if we want to go from 0th node to 6th node. How many different options do we have?1. [0-&amp;gt;1-&amp;gt;3-&amp;gt;4-&amp;gt;5-&amp;gt;6]2. [0-&amp;gt;3-&amp;gt;4-&amp;gt;5-&amp;gt;6]If we are on 0th node, for going to 6th we have 2 options:1. Go to the 1st node [Consider the 1st node or NOT]2. Go to the 3rd node [Consider the 3rd node or NOT]For the 1st node and the 3rd node we also have different choices. This makes our Decision Tree for the path.State Relationship &amp;amp; Recurrence Relations:By considering the above perspective, we can arrange recurrence relation as following:Distance(i, j, k) = min(Distance(i, j, k-1), Distance(i, k, k-1) + Distance(k, j, k-1))Distance(i, j, k) means i to j by considering k vertices, it doesn’t mean k’th (or 0..k) vertex will definitely participate on path. It might or not participate (depends on minimum distance).for example: dp[0][6][6] = min(dp[0][6][5], dp[0][1][5]+dp[1][5][5])State Space Reduction:As we can see, k’th state only depends on (k-1)th state. Therefore, we can reduce from 3D [i][j][k] into [i][j] 2D state.Implementation:# implementation by the brilliant team (!)# time complexity: O(n^3)class Edge:    def __init__(self, start, end, weight):        self.start = start        self.end = end        self.weight = weightclass Graph:    def __init__(self):        self.adj = {} #Adjacency matrix that holds graph data        self.vertexCount = 0    def addVertex(self, vertex):        if vertex in self.adj:            return &quot;Vertex already exists&quot;        if vertex != self.vertexCount:            return &quot;Don&#39;t skip a vertex&quot;        self.adj[vertex] = []        self.vertexCount += 1    def addEdge(self, start, end, weight):        if start not in self.adj:            return &quot;Starting vertex not in graph&quot;        if end not in self.adj:            return &quot;Ending vertex not in graph&quot;        if start == end:            return &quot;Cannot have same start and end vertex&quot;        edge = Edge(start, end, weight)        self.adj[start].append(edge)    def doesEdgeExist(self, start, end):        for vertex in self.adj:            for edge in self.adj[vertex]:                if edge.start == start and edge.end == end:                    return (True, edge)        return (False, None)    def floydwarshall(self):        M = [[99999 for x in range(len(self.adj))] for y in range(len(self.adj))]        for x in range(len(M)):            for y in range(len(M[0])):                if x == y:                    M[x][y] = 0                exists, edge = self.doesEdgeExist(x, y)                if exists:                    M[x][y] = edge.weight        for k in range(len(M)):            for i in range(len(M)):                for j in range(len(M)):                    M[i][j] = min(M[i][j], M[i][k] + M[k][j])        return MFurther research:  Can we optimize this approach for big numbers? (because of time complexity)"
    } ,
  
    {
      "title"    : "Optimal Game Strategy [spontaneous]",
      "article"  : "<div class='article col col-12 animate'> <div class='article__inner'> <div class='article__content'> <h2 class='article__title'> <a href='/opt-gm'>Optimal Game Strategy [spontaneous]</a> </h2> <p class='article__excerpt'>Optimal Game Strategy - DP [part1]</p><div class='article__bottom'> <div class='article-tags__box'><a href='/tag/dp' class='article__tag'>dp</a><a href='/tag/dynamic-programming' class='article__tag'>dynamic-programming</a><a href='/tag/game-theory' class='article__tag'>game-theory</a><a href='/tag/algorithms' class='article__tag'>algorithms</a></div></div></div></div></div>",
      "category" : "",
      "tags"     : "dp, dynamic-programming, game-theory, and algorithms",
      "url"      : "/opt-gm",
      "date"     : "2022-02-17 09:00:00 +0400",
      "content"  : "Optimal Game Strategy - part1 [spontaneous]Some of the well-known CS problems, such as the choosing of an optimal game strategy, may appear to be mentally exhausting at first glance. However, like with other problems, it necessitates a certain point of view from which we must examine it. First and foremost, let us define the problem:  This is a game for two players. There are an even amount of coins placed in a row, hence the row is even. There will be alternating turns. Each round, a player has the option of selecting either the first coin in the row or the last coin in the row and keeping it in his possession. If a player moves first, the goal of the issue is to figure out how much money he or she can earn with certainty up to the greatest amount conceivable.Let’s think the problem from three different perspectives:  we are player-1 and putting ourselves in place of player-2 (game theory) [or vice versa]  We only have a minimal number of coins (it’s a bit of a bottom-up approach).  We have a large number of coins (in a sort of top-down fashion).Perspective#1 (minimax game):Minimax is a decision rule in game theory that is used to minimize the worst-case potential loss; in other words, a player evaluates all of the best opponent answers to his plans and picks the approach that provides the opponent’s best strategy the largest possible payout.Because it is important to minimize the loss incurred when an opponent chooses the strategy that causes the greatest possible loss, the term “minimax” is used to describe a strategy that is useful in analyzing the first player’s decisions when the players move sequentially and when the players move simultaneously. In the latter situation, if certain additional requirements are met, minimax may result in a Nash equilibrium of the game being reached.Minimax is also helpful in combinatorial games, in which a payout is allocated to each location in the game board. The most straightforward example is awarding a “1” to a winning position and a “-1” to a losing position; however, because this is difficult to compute for all but the simplest games, intermediate evaluations (particularly determined for the game in question) are often required. When playing in this context, the first player’s objective is to maximize the assessment of the position, and the second player’s purpose is to decrease the evaluation of the position, the minimax rule comes into play. The “naive” version of minimax is, in essence, the way computers approach games like as chess and Go, while numerous computing enhancements may be made to the “naive” implementation.Suppose player-i chooses strategy si, and the remaining players choose the strategy profile s(-i). If ui(S) denotes the utility function for player-i on strategy profile s, the minimax of a game is defined as  u(i) = min[s-i]max[si]u[i](s(i), s(-i)) In terms of intuition, the minimax (for player-i) may be expressed as one of two equivalent formulations:The minimax is the minimum amount of money that the other players may compel player-i to accept without knowing what player-strategy i’s is before the game begins.When the minimax is informed about the strategies of all other players, he will be the player with the most value, I can assure that.In the same way, the maximin is defined as  u(i) = max[si]min[s-i]u[i](s(i), s(-i)) which can be intuitively understood as either of:  The maximin is the largest value player-i can guarantee when he does not know the strategies of any other player  The maximin is the smallest value the other players can force player-i to receive, while knowing player-i’s strategyPerspective#2 (thinking from bottom to up):Consider the scenario in which there are only 2 or 3 coins left on the table. What are some of the potential edge cases?They can both choose from the front, or player-1 can choose from the front while player-2 can choose from the back (or vice versa).Base case#1 -&amp;gt; there is only one coin on the table, take it.Base case#2 -&amp;gt; there are two coins for choosing, take bigger of them. max(c[0], c[1])State Relationship &amp;amp; Perspective#3:Player-1 wants the best, whereas Player-2 want the best for his/her own. For expression of the state on t moment, [start][end] indice are enough for us.By considering upper ideas &amp;amp; perspectives state transformation can be expressed as like:old_state -&amp;gt; new_state { [i+1][j-1], [i+2][j] } =&amp;gt; {[i], [j]} dp[i][j] = max(c[i] + min(dp[i+2][j], dp[i+1][j-1]), c[j] + min(dp[i+1][j-1], dp[i][j-2]))  if current turn is for player-1, previous was for player-2 and player-2 tried to minimize player-1’s prev result OR maximize his/her result.From the perspective#1 we can easily see that player-01 and player-02 wants to minimize each other’s results. By considering P1 &amp;amp; P2 we can deduce the following state relationship:Implementation:#include&amp;lt;iostream&amp;gt;using namespace std; int findOptimum(int n, int coins[]){    int dp[n][n];     //state variables for dp table, [start][end] available coins on the table    int i,j;     // initialization of dp table    // base case#1, nCoin=1    for(j=0;j&amp;lt;n;j++)    {        dp[j][j]=c[j];    }     // base case#2, nCoin=2, if we have 2 remaining coins: choose max(c[i], c[i+1])    for(j=0;j&amp;lt;n-1;j++)        dp[j][j+1]=max(c[j],c[j+1]);     // building the dp table according to the perspective#1 and perspective#2    for(i=2;i&amp;lt;n;i++)    {        //we will calculate result dp[j][j+i] start..end        for(j=0;j+i&amp;lt;n;j++)        {            int x=c[j]+min(dp[j+2][j+i], dp[j+1][j+i-1]);            int y=c[j+i]+min(dp[j+1][j+i-1], dp[j][j+i-2]);             dp[j][j+i]=max(x,y);        }    }     return dp[0][n-1];}Further research:  Why the number of coins is even?  Are there any other game theory tactics we might use?"
    } ,
  
    {
      "title"    : "Newton-Raphson approach [se1:ch4]",
      "article"  : "<div class='article col col-12 animate'> <div class='article__inner'> <div class='article__content'> <h2 class='article__title'> <a href='/newton-raphson'>Newton-Raphson approach [se1:ch4]</a> </h2> <p class='article__excerpt'>Newton-Raphson approach</p><div class='article__bottom'> <div class='article-tags__box'><a href='/tag/numerical' class='article__tag'>numerical</a><a href='/tag/methods' class='article__tag'>methods</a><a href='/tag/analysis' class='article__tag'>analysis</a><a href='/tag/newton-raphson' class='article__tag'>newton-raphson</a></div></div></div></div></div>",
      "category" : "",
      "tags"     : "numerical, methods, analysis, and newton-raphson",
      "url"      : "/newton-raphson",
      "date"     : "2021-12-21 20:30:00 +0400",
      "content"  : "Newton Raphson approach [se1:ch4]Using the square-root finding technique as an example, this chapter will examine the Newton-Raphson approach in further detail. The in-depth examination and distinctions between Gradient Descent and Newton-Raphson will be the subject of a future season.The Newton-Raphson technique is another numerical method for determining the square root. The root of a nonlinear equation must be bracketed by two estimations using methods like the bisection technique and the false position method. Bracketing approaches are used to accomplish this. Because they reduce the interval between the two estimations in order to zero in on the equation’s root, these approaches are always convergent.The root is not bracketed in the Newton-Raphson approach. When it comes to solving an equation, just one initial guess of the root is required to get the iterative process started.As a result, it might be considered an open approach. Open approaches may or may not converge, but if they do, it will be substantially faster than with bracketing.Derivation:In general, the Newton-Raphson technique is founded on the idea that if the original estimation for the root of f(x)=0 is at xi, then drawing the tangent to the curve at f(xi) will result in a better estimate of the root, as will drawing the tangent to the curve at f(xi).Using the definition of the slope(tangent) of a function, at x=xi.Algorithm for this method:  Compute values of f(x) and f’(x) for given initial x, f’(x) is derivative of f(x) w.r.t x  Compute d: d = f(x) / f’(x)  While d is greater than allowed error ε [iterate till the convergence]          d = f(x) / f’(x)      x = x – d      Implementation:// C++ program for implementation of Newton Raphson Method for// solving equations#include&amp;lt;bits/stdc++.h&amp;gt;#define EPSILON 0.001 // Tolerance errorusing namespace std; // An example function whose solution is determined using// Bisection Method. The function is x^3 - x^2  + 2double func(double x){    return x*x*x - x*x + 2;} // Derivative of the above function which is 3*x^x - 2*xdouble derivFunc(double x){    return 3*x*x - 2*x;} // Function to find the rootvoid newtonRaphson(double x){    double h = func(x) / derivFunc(x);    while (abs(h) &amp;gt;= EPSILON)    {        h = func(x)/derivFunc(x);          // x(i+1) = x(i) - f(x) / f&#39;(x)          x = x - h;    }     cout &amp;lt;&amp;lt; &quot;The value of the root is : &quot; &amp;lt;&amp;lt; x;} // Driver program to test aboveint main(){    double x0 = -20; // Initial values assumed    newtonRaphson(x0);    return 0;}Pros:  It is the most efficient approach to solving nonlinear equations.  In addition, it may be used to solve a system of nonlinear equations, nonlinear differential equations, and nonlinear integral equations, among others.  As a result, this approach is relatively quick when compared to other methods due to the quadric order of convergence (i.e., of second-order).  It is really straightforward to implement on a computer.Cons:  If the derivative of the function f(x) is not a simple function, then this procedure gets difficult.  This approach necessitates a considerable deal of care and sensitivity in the selection of its approximation parameters.  We must assess two values f(x) and f’(x) for some x in each iteration of the algorithm."
    } ,
  
    {
      "title"    : "Approximation - Error Analysis [se1:ch3]",
      "article"  : "<div class='article col col-12 animate'> <div class='article__inner'> <div class='article__content'> <h2 class='article__title'> <a href='/error-analysis'>Approximation - Error Analysis [se1:ch3]</a> </h2> <p class='article__excerpt'>Error Analysis of Bisection method</p><div class='article__bottom'> <div class='article-tags__box'><a href='/tag/numerical' class='article__tag'>numerical</a><a href='/tag/methods' class='article__tag'>methods</a><a href='/tag/error' class='article__tag'>error</a><a href='/tag/analysis' class='article__tag'>analysis</a></div></div></div></div></div>",
      "category" : "",
      "tags"     : "numerical, methods, error, and analysis",
      "url"      : "/error-analysis",
      "date"     : "2021-12-20 18:01:00 +0400",
      "content"  : "Approximation - Error Analysis [se1:ch3]While solving a mathematical model using numerical approaches, we can use errors to minimize errors. When doing a numerical analysis, mistakes will inevitably occur. To address the problem of errors, we must first  determine the source of the error,  quantify the error, and then  minimize the error in accordance with our requirements.Here, we’ll focus on item 2, i.e., how to measure mistakes.What is a TRUE Error in this context? TRUE error, represented by E, is defined as the difference between the true value (also known as the precise value) and the estimated value.  True Error = True Value - Approximate ValueWhat is relative true error, and how does it affect you?The ratio between the true error and the true value is symbolized by the letter t, and it is defined as the true error divided by the true value.  Relative True Error = True Error / True ValueWhat is approximate error? True errors are calculated only if true values are known. We will, however, most likely not have the luxury of knowing the exact numbers, as there is no reason to search for approximate values if you already know the true values. As a result, when we use numerical methods to solve an issue, we will only have access to approximate data. In these types of situations, we must understand how to measure inaccuracy. The amount of the estimated mistake does not indicate how serious the inaccuracy is, though.  Approximate Error = Current Approximation - Previous Approximation  Relative Approximate Error = Approximate Error / Current Approximation"
    } ,
  
    {
      "title"    : "Bisection Method [se1:ch2]",
      "article"  : "<div class='article col col-12 animate'> <div class='article__inner'> <div class='article__content'> <h2 class='article__title'> <a href='/bisection-method-ch2'>Bisection Method [se1:ch2]</a> </h2> <p class='article__excerpt'>Bisection Method introduction</p><div class='article__bottom'> <div class='article-tags__box'><a href='/tag/numerical' class='article__tag'>numerical</a><a href='/tag/methods' class='article__tag'>methods</a><a href='/tag/analysis' class='article__tag'>analysis</a><a href='/tag/bisection' class='article__tag'>bisection</a></div></div></div></div></div>",
      "category" : "",
      "tags"     : "numerical, methods, analysis, and bisection",
      "url"      : "/bisection-method-ch2",
      "date"     : "2021-12-08 19:30:53 +0400",
      "content"  : "Bisection Method [se1:ch2]Consider the following scenario: we have a nonlinear equation and are attempting to solve it using a computer program. For the nonlinear equation, what strategy can the CPU employ in order to compute a solution? Alternatively, from what point of view would we address that challenge in terms of efficacy?In light of the fundamental architecture of the CPU, how can we develop an algorithm for finding a solution to this problem?Following the development of an algorithm, we will apply the answer to that problem to substantial challenges like Binary Search.Before diving into the algorithm, there are some edge cases we need to analyze.case1: Let’s pretend we have a function that looks like this, and it has crossed the Ox axis once.:T1: We know from mathematics that if a function is real, continuous, and changes sign between two points, then there must be at least one root between the two points in the function’s domain.case2: The function has roots, but the sign of the function has not changed between points.T2: It’s possible that roots of the equation f(x) = 0 still exist between two positions where f(x) doesn’t change sign between xl and xu points.case3: Any real root of the function does not exist; in addition, there is no change in its sign from one point to the next.T3: It’s possible that roots of the equation f(x) = 0 don’t exist between two positions where f(x) doesn’t change sign between xl and xu points.case4: There may be more than one root for the equation between two points if the function changes the sign between them. If the function changes the sign between two points, there may be more than one root for the equation between them.  The core intuition behind numerical approaches is based on approximation &amp;amp; convergence, as we discussed in the previous chapter.The TOL error notion is not important to this chapter; we’ll cover error analysis in a later chapter.#include&amp;lt;bits/stdc++.h&amp;gt;using namespace std;#define TOL 0.01 // threshold for error // An example function whose solution is determined using// Bisection Method. The function is x^3 - x^2  + 2double func(double x){    return x*x*x - x*x + 2;} // Prints root of func(x) with error of TOLvoid bisection(double a, double b){    if (func(a) * func(b) &amp;gt;= 0)    {        cout &amp;lt;&amp;lt; &quot;You have not assumed right a and b\n&quot;;        return;    }     double c = a;    while ((b-a) &amp;gt;= TOL)    {        // Find middle point        c = (a+b)/2;         // Check if middle point is root        if (func(c) == 0.0)            break;         // Decide the side to repeat the steps        else if (func(c)*func(a) &amp;lt; 0)            b = c;        else            a = c;    }    cout &amp;lt;&amp;lt; &quot;The value of root is : &quot; &amp;lt;&amp;lt; c;} // Driver program to test above functionint main(){    // Initial values assumed    double a =-200, b = 300;    bisection(a, b);    return 0;} Pros &amp;amp; Cons of using the bisection approach:Pros:  The bisection approach is always convergent, regardless of the situation. Due to the fact that the approach brackets the root, the method is certain to converge.  As the number of repetitions is increased, the interval is reduced by half. As a result, the inaccuracy in the solution of the equation may be guaranteed.Cons:      The convergence of the bisection method is slow as it is simply based on halvingthe interval.        If one of the initial guesses is closer to the root, it will take a larger number ofiterations to reach the root.  In the next chapter, we will discuss error analysis."
    } ,
  
    {
      "title"    : "Numerical Methods - need [se1:ch1]",
      "article"  : "<div class='article col col-12 animate'> <div class='article__inner'> <div class='article__content'> <h2 class='article__title'> <a href='/numerical-methods-intro'>Numerical Methods - need [se1:ch1]</a> </h2> <p class='article__excerpt'>Numerical Analysis &amp; Methods Introduction</p><div class='article__bottom'> <div class='article-tags__box'><a href='/tag/numerical' class='article__tag'>numerical</a><a href='/tag/methods' class='article__tag'>methods</a><a href='/tag/analysis' class='article__tag'>analysis</a></div></div></div></div></div>",
      "category" : "",
      "tags"     : "numerical, methods, and analysis",
      "url"      : "/numerical-methods-intro",
      "date"     : "2021-12-01 15:01:35 +0400",
      "content"  : "Numerical Methods - need [se1:ch1]Have you ever wondered how computer software determines the square root of a given value?  “Computational thinking vs. Human thinking” is the equivalent of this question.Doing the math on paper is different from CPU. By design, computers solve problems iteratively. Innate methods must be adapted in order to deal with such a situation.This article’s primary goal is to foster intuition:  Understand the requirement for numerical methods  Go through the processes of solving a specific problem (mathematical modeling, solution, and implementation).Solving engineering challenges necessitates the use of mathematical models. These mathematical models might be generated from actual data or from concepts found in engineering and science. A wide variety of mathematical methods, such as differentiation, nonlinear equations, simultaneous linear equations, curve fitting by interpolation or regression, integration, and differential equations are frequently required when building mathematical models. Some of these mathematical operations can be solved precisely, as you probably learned to do in your calculus studies, but for the most part, they must be approximated numerically. Approximate answers to mathematical problems are provided by numerical methods. These issues might arise in any engineering discipline. As a result, any answer you acquire using these methods will be approximate rather than accurate. However, they provide the solution more quickly than standard approaches and are also simple to program.The main applications of numerical methods are:  Adaptive computation (we will discuss this topic separately)  Solving linear and nonlinear equations and determining the true roots. There are several ways available, such as bisection, Newton-Raphson, and so on.  Any value in the range of a table of values may be obtained by using interpolation. It is capable of resolving readings with equal spacing, and Newton’s general technique is inferred for ways with uneven spacing.  A good estimate and a simple approach are to fit certain points to a curve.  On the basis of the assumption that integration can be computed using a simple procedure, the definite integral is the area enclosed by the given curve. These approaches are quite good at estimating the area. There are a variety of techniques, such as Simpson’s rule.  Solving partial differential equations.As an engineer or scientist, you will employ numerical methods to address an issue. Let’s have a look at an example of this in action. As a starting point, let’s take a look at the stages that go into fixing an engineering issue. In order to begin, you must first identify the problem. Defining the problem is the first step in solving it since if you don’t know-how, you won’t be able to. You need to write a detailed explanation of the issue you’re dealing with, including what it is and what we’re searching for before you can begin working on it. After that, you may create a mathematical model of it, however, others would say that an experimental model is required. That is perfectly OK. Whatever strategy you use for solving the problem will determine whether you construct a mathematical model or an experimental model. Even an experimental model must require a mathematical model at some point if the problem is to be solved or presented in an understandable manner. Using our numerical methodologies, we will limit the applicability after we’ve established a mathematical model. If you wish to find a solution, you’ll need to work out a mathematical model.Depending on how you solve the mathematical model, you may utilize analytical methods, numerical methods, or even a package program to accomplish your goal. When students or others think they’ve finished with a mathematical model, they often mistakenly believe that they’ve completed their work; this isn’t the case for your employer or anybody else. Instead of merely searching for a mathematical answer, they want to know how you plan to put that solution into action so that the problem may be resolved.For the next chapter, we are diving into the Bisection Analysis &amp;amp; Newton-Raphson Method."
    } ,
  
    {
      "title"    : "Binary Search - survival guide [se1:ch6]",
      "article"  : "<div class='article col col-12 animate'> <div class='article__inner'> <div class='article__content'> <h2 class='article__title'> <a href='/binary-search-2'>Binary Search - survival guide [se1:ch6]</a> </h2> <p class='article__excerpt'>Binary Search - Search Space Reduction [continued]</p><div class='article__bottom'> <div class='article-tags__box'><a href='/tag/binary' class='article__tag'>binary</a><a href='/tag/search' class='article__tag'>search</a><a href='/tag/binary-search' class='article__tag'>binary-search</a></div></div></div></div></div>",
      "category" : "",
      "tags"     : "binary, search, and binary-search",
      "url"      : "/binary-search-2",
      "date"     : "2021-11-23 18:01:00 +0400",
      "content"  : "Binary Search - survival guide [se1:ch6]As I have stated in [se1:ch2], [se1:ch5], there are different search space reduction scenarios.SCENARIO-2: This situation is an enhanced version of the Binary Search technique. It is used to search for an element or condition that necessitates accessing the current index in the array as well as the index of its immediate right neighbor in the array.  One question arises in this context: why is left=mid+1?Because we are doing integer division, which index is the most dominant in the final result? Because the integer division ignores the portions after a point, the smaller element always dominates the outcome in all cases.  It’s as if the left side is equipped with a magnet, which attracts the right side.int binarySearch(vector&amp;lt;int&amp;gt;&amp;amp; nums, int target){  if(nums.size() == 0)    return -1;  int left = 0, right = nums.size();  while(left &amp;lt; right){    // Prevent (left + right) overflow    int mid = left + (right - left) / 2;    if(nums[mid] == target){ return mid; }    else if(nums[mid] &amp;lt; target) { left = mid + 1; }    else { right = mid; }  }  // Post-processing:  // End Condition: left == right  if(left != nums.size() &amp;amp;&amp;amp; nums[left] == target) return left;  return -1;}The following are the main focuses:  An advanced method of implementing Binary Search.  The Search Condition must have access to the element’s immediate right neighbor in order to be effective.  Determine if a condition is satisfied by looking at the element’s right neighbor and then choosing whether to travel left or right.  It is necessary to perform post-processing to ensure that the Search Space is at least 2 in size at each stage. When you have only one element remaining in the loop/recursion, it is over. It is necessary to determine if the remaining element satisfies the criteria."
    } ,
  
    {
      "title"    : "Binary Search - survival guide [se1:ch5]",
      "article"  : "<div class='article col col-12 animate'> <div class='article__inner'> <div class='article__content'> <h2 class='article__title'> <a href='/binary-search-1'>Binary Search - survival guide [se1:ch5]</a> </h2> <p class='article__excerpt'>Binary Search - [Intro &amp; Search Space Reduction]</p><div class='article__bottom'> <div class='article-tags__box'><a href='/tag/binary' class='article__tag'>binary</a><a href='/tag/search' class='article__tag'>search</a><a href='/tag/binary-search' class='article__tag'>binary-search</a></div></div></div></div></div>",
      "category" : "",
      "tags"     : "binary, search, and binary-search",
      "url"      : "/binary-search-1",
      "date"     : "2021-11-22 18:01:00 +0400",
      "content"  : "Binary Search - survival guide [se1:ch5]From the standpoint of difficulty, binary search is one of the most “deceptive” algorithms available:)At first appearance, it appears to be a simple method to build and an approachable algorithm. However, when you look at the specifics, you will notice that the techniques are counter-intuitive, and this will prove to be intimidating in the long run. But there’s no reason to be concerned when you know where it comes from. Over the course of chapters [1 to 4], we examined the mathematical foundations of the Binary search, including approximation methods, numerical analysis, search space reduction, and so on.There are several terms in computer science for binary search, which is also known as half-interval, logarithmic, or binary chop. Its purpose is to locate the location of an object in an ordered array. An array is compared to its center member when using a binary search. After determining that the target value can’t be found in one half, the remaining half is searched again, selecting a middle element from each half and comparing it to the target value until the target value is discovered. An empty half of the array indicates that your target was not found in the search results.O(logn) comparisons are made in the worst-case scenario when binary search runs in logarithmic time (for sorted array). The number of entries in an array determines how many comparisons are made.Except for tiny arrays, binary search is quicker than linear search. However, in order to use binary search, the array must first be sorted. Specialized data structures like hash tables, which can be searched more quickly than the binary search algorithm, are available. In addition to locating the next-smallest or next-largest element in the array in relation to the target, binary search may also be used to tackle a broader spectrum.As I have stated, Binary Search is one of the “deceptive” algorithms. It’s one of the most buggy implemented algorithms in the world. Therefore, I wanted to show you the idea behind it (where it comes from). As a bisection method [se1:ch2], it’s always convergent. Some historical buggy affections to the world:https://ai.googleblog.com/2006/06/extra-extra-read-all-about-it-nearly.htmlhttps://dev.to/matheusgomes062/a-bug-was-found-in-java-after-almost-9-years-of-hiding-2d4k  TLDR: There is a limit to the int data type, so when we add two really large numbers, we get an overflow and a negative value, which, when split by two, causes the issue.In chapters [6-8], we are going through 3 different search space reduction scenarios.SCENARIO-1: converge to the 1 element remaining in the search space. It is the most basic and elementary form of Binary Search. It is the standard Binary Search Template that most high schools or universities use when they first teach students computer science.  Most basic and elementary form of Binary Search  Search Condition can be determined without comparing to the element’s neighbors (or use specific elements around it)  No post-processing required because at each step, you are checking to see if the element has been found. If you reach the end, then you know the element is not foundint binarySearch(vector&amp;lt;int&amp;gt;&amp;amp; nums, int target){  if(nums.size() == 0)    return -1;  int left = 0, right = nums.size() - 1;  while(left &amp;lt;= right){    // Prevent (left + right) overflow    int mid = left + (right - left) / 2;    if(nums[mid] == target){ return mid; }    else if(nums[mid] &amp;lt; target) { left = mid + 1; }    else { right = mid - 1; }  }  // End Condition: left &amp;gt; right  return -1;}Iterations:For the next chapter we are going to discuss other search space scenarios."
    } 
  
]
